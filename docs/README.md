Since most people speak faster than they write, speech recognition software 
provides a simple way to get words into a document without having to be 
delayed in the process. And also, if either of the side is unaware of the 
language of communication, the cycle will be incomplete. So, we need a 
system that can bridge this language barrier. Whisper is an Automatic 
Speech Recognition (ASR) system trained on 680,000 hours of multilingual 
and multitask supervised data collected from the web. 

###Ideas:
It is a sequence-to-sequence model which is trained on various speech 
processing tasks, including multilingual speech transcription, 96 different 
languages to English languages translation, spoken language identification, 
and voice activity detection. It performs well even on diverse accents and 
technical language. Whisper approaches “human-level robustness and 
accuracy” on English speech recognition. 

###Features:
❖ Speech Transcription
❖ Speech Translation (97 different languages)
❖ Spoken Language Identification
❖ Voice Activity Detection
❖ Video to Text Transcription and Translation
❖ Podcast to Text Transcription and Translation

###Development Tools:
♦ Language: (Python, JavaScript/Typescript)
♦ Deep Learning Model: Whisper (OpenAI)
♦ User interface:
 For Web: Next Js
 For Mobile: React Native
 For Chrome Extension: Next Js (Tentative)
♦ Version control: Git
♦ Mono repo: Turborepo
♦ Project Management: Trello
♦ Designing: Figma (Tentative)

###Functional requirements:
▪ The software should allow users to record their voice.
▪ The software must implement multilingual speech transcription.
▪ The software must translate any languages to English languages.
▪ The software must detect the spoken Language.
▪ The software must identify the voice activity.
▪ The software should convert any videos to audios.
▪ The software must show the details of supporting Language.
